{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500fa887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU Available: []\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 0: INSTALL & IMPORTS\n",
    "# ==============================\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "from nilearn import plotting, image\n",
    "from nilearn.maskers import NiftiMasker\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv3D, MaxPooling3D, Dense, Dropout, \n",
    "    Flatten, BatchNormalization, GlobalAveragePooling3D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5237bf",
   "metadata": {},
   "source": [
    "# 3D CNN for fMRI-Based ASD Detection\n",
    "\n",
    "**Problem Statement:** Developing Predictive Models for Early ASD Detection in Young Children Based on fMRI Scans\n",
    "\n",
    "## Dataset: ABIDE-II (Autism Brain Imaging Data Exchange II)\n",
    "\n",
    "**ABIDE-II** is the most comprehensive autism neuroimaging dataset for young children:\n",
    "- **Size**: 1,000+ participants across 19 sites\n",
    "- **Target Population**: 372 young children (ages 5-10 years) for early detection\n",
    "  - **168 ASD** and **204 Control** subjects\n",
    "- **Data Type**: Resting-state fMRI (rs-fMRI) scans\n",
    "- **Preprocessing**: DPARSF (Data Processing Assistant for Resting-State fMRI)\n",
    "- **Format**: NIfTI files (.nii.gz)\n",
    "\n",
    "## üì• DATA DOWNLOAD REQUIRED\n",
    "\n",
    "**‚ö†Ô∏è Important:** ABIDE-II preprocessed data must be downloaded manually from NITRC.\n",
    "\n",
    "### Steps to Download:\n",
    "1. Visit: https://fcon_1000.projects.nitrc.org/indi/abide/\n",
    "2. Register for a free NITRC account\n",
    "3. Download **ABIDE-II Preprocessed Data (DPARSF pipeline)**\n",
    "4. Select **filt_noglobal strategy** (recommended for ASD studies)\n",
    "5. Extract files to: `./abide2_fmri_data/`\n",
    "\n",
    "### Required File Structure:\n",
    "```\n",
    "./abide2_fmri_data/\n",
    "  ‚îú‚îÄ‚îÄ ABIDEII-EMC_1_0029864/\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ ABIDEII-EMC_1_0029864_func_preproc.nii.gz\n",
    "  ‚îú‚îÄ‚îÄ ABIDEII-EMC_1_0029866/\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ ABIDEII-EMC_1_0029866_func_preproc.nii.gz\n",
    "  ‚îî‚îÄ‚îÄ ... (372 subjects total)\n",
    "```\n",
    "\n",
    "### DPARSF Preprocessing Pipeline:\n",
    "1. **Slice timing correction** - accounts for different acquisition times\n",
    "2. **Realignment** - corrects head motion (6-parameter rigid body)\n",
    "3. **Co-registration** - aligns T1 structural to functional images\n",
    "4. **Segmentation** - separates GM, WM, CSF\n",
    "5. **Normalization** - DARTEL registration to MNI space\n",
    "6. **Motion artifact removal** - Friston 24-parameter model\n",
    "7. **Nuisance regression** - removes WM, CSF signals\n",
    "8. **Temporal filtering** - 0.01-0.1 Hz bandpass\n",
    "9. **Spatial smoothing** - 6mm FWHM Gaussian kernel\n",
    "\n",
    "### Why DPARSF + filt_noglobal?\n",
    "- **DPARSF**: Most comprehensive preprocessing for ASD research\n",
    "- **filt_noglobal**: Avoids GSR artifacts that may distort ASD group differences\n",
    "\n",
    "## Requirements:\n",
    "- nibabel: Read NIfTI files\n",
    "- scipy: Image resampling\n",
    "- tensorflow: Deep learning framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d953621",
   "metadata": {},
   "source": [
    "## Step 1: Data Download Instructions\n",
    "\n",
    "### ‚ö†Ô∏è Important Note: ABIDE-II Data Availability\n",
    "\n",
    "**ABIDE-II preprocessed fMRI data is NOT available on public AWS S3.** Only ABIDE-I is accessible via S3.\n",
    "\n",
    "### Option 1: Download ABIDE-II Manually (Recommended for Production)\n",
    "\n",
    "**NITRC (NeuroImaging Tools & Resources Collaboratory):**\n",
    "1. Visit: https://fcon_1000.projects.nitrc.org/indi/abide/\n",
    "2. Register for free account\n",
    "3. Download ABIDE-II preprocessed data (DPARSF pipeline)\n",
    "4. Extract to `./abide2_fmri_data/` directory\n",
    "\n",
    "**OpenNeuro:**\n",
    "- ABIDE-II collection: https://openneuro.org/\n",
    "- Raw data available, requires preprocessing\n",
    "\n",
    "**File Structure After Download:**\n",
    "```\n",
    "./abide2_fmri_data/\n",
    "  ‚îî‚îÄ‚îÄ ABIDEII-EMC_1_0029864/\n",
    "      ‚îî‚îÄ‚îÄ ABIDEII-EMC_1_0029864_func_preproc.nii.gz\n",
    "  ‚îî‚îÄ‚îÄ ABIDEII-EMC_1_0029866/\n",
    "      ‚îî‚îÄ‚îÄ ABIDEII-EMC_1_0029866_func_preproc.nii.gz\n",
    "  ...\n",
    "```\n",
    "\n",
    "### Option 2: Use ABIDE-I via AWS S3 (Available for Testing)\n",
    "\n",
    "**ABIDE-I data** IS available on public AWS S3 (no credentials required).\n",
    "\n",
    "**URL Template:**\n",
    "```\n",
    "https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/[pipeline]/[strategy]/[derivative]/[FILE_ID]_[derivative].[ext]\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `[pipeline]`: **cpac** | dparsf | ccs | niak\n",
    "- `[strategy]`: **filt_noglobal** (recommended) | filt_global | nofilt_global | nofilt_noglobal\n",
    "- `[derivative]`: **func_preproc** (preprocessed 4D fMRI)\n",
    "- `[FILE_ID]`: Site + Subject (e.g., `KKI_0050822`, `NYU_0050952`)\n",
    "\n",
    "**Example URL for ABIDE-I:**\n",
    "```\n",
    "https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/cpac/filt_noglobal/func_preproc/NYU_0050952_func_preproc.nii.gz\n",
    "```\n",
    "\n",
    "**File Sizes:**\n",
    "- `func_preproc` (4D fMRI): **30-200 MB per subject**\n",
    "\n",
    "### Why DPARSF + filt_noglobal?\n",
    "- **DPARSF**: Most comprehensive preprocessing for ASD research\n",
    "- **filt_noglobal**: Avoids GSR artifacts that may distort ASD group differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecf475c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ./abide2_fmri_data\n",
      "Pipeline: DPARSF (Data Processing Assistant for Resting-State fMRI)\n",
      "Strategy: filt_noglobal (filtered, no GSR - recommended for ASD)\n",
      "Data source: AWS S3 - fcp-indi.s3.amazonaws.com (public, no credentials)\n",
      "‚úì Ready to download ABIDE-II data. Run next cell to load phenotypic file.\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 1: DOWNLOAD ABIDE-II DATA\n",
    "# ==============================\n",
    "\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Set data directory for ABIDE-II\n",
    "data_dir = \"./abide2_fmri_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "def download_abide_fmri_aws(file_id, output_dir=\"./abide2_fmri_data\", pipeline=\"dparsf\", strategy=\"filt_noglobal\"):\n",
    "    \"\"\"\n",
    "    Download a single preprocessed fMRI file from AWS S3 (ABIDE-II)\n",
    "    Requires internet access but no credentials for public data\n",
    "    \n",
    "    Args:\n",
    "        file_id: FILE_ID from ABIDE-II (e.g., 'ABIDEII-BNI_1_0029006')\n",
    "        output_dir: Local directory to save files\n",
    "        pipeline: dparsf (recommended for ABIDE-II)\n",
    "        strategy: filt_noglobal (recommended for ASD studies)\n",
    "    \n",
    "    Returns:\n",
    "        Path to downloaded file or None if failed\n",
    "    \"\"\"\n",
    "    # Remove \"ABIDEII-\" prefix for S3 URL (S3 uses format: EMC_1_0029864)\n",
    "    s3_file_id = file_id.replace('ABIDEII-', '') if file_id.startswith('ABIDEII-') else file_id\n",
    "    \n",
    "    # FCP-INDI S3 bucket (public, no credentials needed)\n",
    "    base_url = \"https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs\"\n",
    "    url = f\"{base_url}/{pipeline}/{strategy}/func_preproc/{s3_file_id}_func_preproc.nii.gz\"\n",
    "    \n",
    "    output_path = Path(output_dir) / file_id\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    output_file = output_path / f\"{file_id}_func_preproc.nii.gz\"\n",
    "    \n",
    "    if output_file.exists():\n",
    "        return str(output_file)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Downloading {file_id}...\", end=' ')\n",
    "        urllib.request.urlretrieve(url, output_file, reporthook=lambda b,c,s: None)\n",
    "        file_size_mb = output_file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"‚úì ({file_size_mb:.1f} MB)\")\n",
    "        return str(output_file)\n",
    "    except urllib.error.HTTPError as e:\n",
    "        if output_file.exists():\n",
    "            output_file.unlink()\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        if output_file.exists():\n",
    "            output_file.unlink()\n",
    "        return None\n",
    "\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Pipeline: DPARSF (Data Processing Assistant for Resting-State fMRI)\")\n",
    "print(f\"Strategy: filt_noglobal (filtered, no GSR - recommended for ASD)\")\n",
    "print(f\"Data source: AWS S3 - fcp-indi.s3.amazonaws.com (public, no credentials)\")\n",
    "print(\"‚úì Ready to download ABIDE-II data. Run next cell to load phenotypic file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7bf7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded ABIDE-II phenotypic data: 1114 total subjects\n",
      "\n",
      "============================================================\n",
      "ABIDE-II fMRI Dataset - YOUNG CHILDREN (Age 5-10 years)\n",
      "============================================================\n",
      "Total subjects in ABIDE-II: 1114\n",
      "Young children (5-10 years): 372\n",
      "\n",
      "Class Distribution (Young Children):\n",
      "  ASD: 168\n",
      "  Control: 204\n",
      "  Age range: 5.1 - 10.0 years\n",
      "\n",
      "Example fMRI subjects from ABIDE-II (Young Children):\n",
      "          SITE_ID  SUB_ID                FILE_ID  AGE_AT_SCAN  SEX  DX_GROUP  label\n",
      "58  ABIDEII-EMC_1   29864  ABIDEII-EMC_1_0029864     9.013005    1         1      1\n",
      "60  ABIDEII-EMC_1   29866  ABIDEII-EMC_1_0029866     8.720055    1         1      1\n",
      "61  ABIDEII-EMC_1   29867  ABIDEII-EMC_1_0029867     8.517454    2         1      1\n",
      "63  ABIDEII-EMC_1   29869  ABIDEII-EMC_1_0029869     8.793977    1         1      1\n",
      "64  ABIDEII-EMC_1   29870  ABIDEII-EMC_1_0029870     8.618754    1         1      1\n",
      "65  ABIDEII-EMC_1   29871  ABIDEII-EMC_1_0029871     7.455168    2         1      1\n",
      "66  ABIDEII-EMC_1   29872  ABIDEII-EMC_1_0029872     9.147159    1         1      1\n",
      "67  ABIDEII-EMC_1   29873  ABIDEII-EMC_1_0029873     6.776181    1         1      1\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 2: LOAD ABIDE-II fMRI DATA FOR YOUNG CHILDREN\n",
    "# ==============================\n",
    "\n",
    "pheno_file = \"ABIDEII_Composite_Phenotypic.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(pheno_file, encoding='latin1')\n",
    "    df.columns = df.columns.str.strip()\n",
    "    print(f\"‚úì Loaded ABIDE-II phenotypic data: {df.shape[0]} total subjects\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: {pheno_file} not found!\")\n",
    "    print(\"   Download from: https://fcon_1000.projects.nitrc.org/indi/abide/\")\n",
    "    raise\n",
    "\n",
    "# Create labels: 1 = ASD, 0 = Control (DX_GROUP: 1=ASD, 2=Control)\n",
    "df['label'] = df['DX_GROUP'].map({1: 1, 2: 0})\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# Create FILE_ID from SITE_ID and SUB_ID (format: SITE_SUB_ID)\n",
    "# Example: ABIDEII-BNI_1 + 29006 -> ABIDEII-BNI_1_0029006\n",
    "df['FILE_ID'] = df['SITE_ID'].astype(str) + '_' + df['SUB_ID'].astype(str).str.zfill(7)\n",
    "\n",
    "# ===== FILTER FOR YOUNG CHILDREN (5-10 years) =====\n",
    "# Early ASD Detection in School-Age Children\n",
    "# Note: ABIDE-II minimum age is 5.1 years (no infants/toddlers available)\n",
    "MIN_AGE = 5\n",
    "MAX_AGE = 10\n",
    "df_filtered = df[(df['AGE_AT_SCAN'] >= MIN_AGE) & (df['AGE_AT_SCAN'] <= MAX_AGE)].copy()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ABIDE-II fMRI Dataset - YOUNG CHILDREN (Age {MIN_AGE}-{MAX_AGE} years)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total subjects in ABIDE-II: {len(df)}\")\n",
    "print(f\"Young children (5-10 years): {len(df_filtered)}\")\n",
    "\n",
    "if len(df_filtered) > 0:\n",
    "    print(f\"\\nClass Distribution (Young Children):\")\n",
    "    print(f\"  ASD: {int((df_filtered['label']==1).sum())}\")\n",
    "    print(f\"  Control: {int((df_filtered['label']==0).sum())}\")\n",
    "    print(f\"  Age range: {df_filtered['AGE_AT_SCAN'].min():.1f} - {df_filtered['AGE_AT_SCAN'].max():.1f} years\")\n",
    "    \n",
    "    print(f\"\\nExample fMRI subjects from ABIDE-II (Young Children):\")\n",
    "    print(df_filtered[['SITE_ID', 'SUB_ID', 'FILE_ID', 'AGE_AT_SCAN', 'SEX', 'DX_GROUP', 'label']].head(8).to_string())\n",
    "    \n",
    "    # Use filtered dataset\n",
    "    df = df_filtered\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: No young children found in ABIDE-II in age range {MIN_AGE}-{MAX_AGE} years\")\n",
    "    print(f\"Available age range in dataset: {df['AGE_AT_SCAN'].min():.1f} - {df['AGE_AT_SCAN'].max():.1f} years\")\n",
    "    print(f\"Using all subjects instead (age filtering disabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee99184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì fMRI preprocessing functions defined (optimized for young children ages 5-10)\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 3: fMRI PREPROCESSING FOR YOUNG CHILDREN\n",
    "# ==============================\n",
    "# Optimized for resting-state fMRI (rs-fMRI) data from ABIDE-II\n",
    "# Processing: 4D -> 3D (temporal mean) -> Resample -> Normalize\n",
    "\n",
    "def load_and_preprocess_fmri(file_path, target_shape=(64, 64, 64)):\n",
    "    \"\"\"\n",
    "    Load and preprocess resting-state fMRI (rs-fMRI) scan\n",
    "    Assumes input is DPARSF preprocessed (filt_noglobal strategy)\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to func_preproc.nii.gz file (4D fMRI volume)\n",
    "        target_shape: Target dimensions (x, y, z) after resampling\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed 3D numpy array (single 3D volume) or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.ndimage import zoom\n",
    "        \n",
    "        # Load NIfTI file\n",
    "        img = nib.load(file_path)\n",
    "        data = img.get_fdata()\n",
    "        \n",
    "        # Verify 4D fMRI (spatial + temporal dimensions)\n",
    "        if len(data.shape) != 4:\n",
    "            print(f\"  Warning: Expected 4D fMRI, got shape {data.shape}\")\n",
    "            return None\n",
    "        \n",
    "        # Take temporal mean to convert 4D -> 3D\n",
    "        # Reduces temporal noise while preserving spatial structure\n",
    "        data_3d = np.mean(data, axis=-1)\n",
    "        \n",
    "        # Resample to target shape for model input\n",
    "        if data_3d.shape != target_shape:\n",
    "            zoom_factors = [t/s for t, s in zip(target_shape, data_3d.shape)]\n",
    "            data_resampled = zoom(data_3d, zoom_factors, order=1)\n",
    "        else:\n",
    "            data_resampled = data_3d\n",
    "        \n",
    "        # Normalize: Z-score normalization\n",
    "        # (mean=0, std=1) for stable neural network training\n",
    "        data_norm = (data_resampled - data_resampled.mean()) / (data_resampled.std() + 1e-8)\n",
    "        \n",
    "        return data_norm\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_fmri_dataset(df, data_dir, target_shape=(64, 64, 64), max_samples=None):\n",
    "    \"\"\"\n",
    "    Load rs-fMRI dataset (func_preproc) from ABIDE-II\n",
    "    \n",
    "    Args:\n",
    "        df: Phenotypic dataframe with FILE_ID and labels\n",
    "        data_dir: Directory containing downloaded fMRI files\n",
    "        target_shape: Resampling target\n",
    "        max_samples: Maximum number of subjects to load\n",
    "    \n",
    "    Returns:\n",
    "        X (fMRI scans), y (labels), file_ids (subject identifiers)\n",
    "    \"\"\"\n",
    "    X, y, file_ids = [], [], []\n",
    "    df_subset = df.head(max_samples) if max_samples else df\n",
    "    \n",
    "    for idx, row in df_subset.iterrows():\n",
    "        file_id = row['FILE_ID']\n",
    "        label = int(row['label'])\n",
    "        age = row['AGE_AT_SCAN']\n",
    "        \n",
    "        # Try multiple file path patterns for func_preproc\n",
    "        file_path = Path(data_dir) / file_id / f\"{file_id}_func_preproc.nii.gz\"\n",
    "        if not file_path.exists():\n",
    "            file_path = Path(data_dir) / f\"{file_id}_func_preproc.nii.gz\"\n",
    "        \n",
    "        if file_path.exists():\n",
    "            data = load_and_preprocess_fmri(str(file_path), target_shape)\n",
    "            if data is not None:\n",
    "                X.append(data)\n",
    "                y.append(label)\n",
    "                file_ids.append(file_id)\n",
    "    \n",
    "    if len(X) > 0:\n",
    "        # Add channel dimension for 3D CNN input: (batch, depth, height, width, channels)\n",
    "        X = np.array(X)[..., np.newaxis]\n",
    "        y = np.array(y)\n",
    "    else:\n",
    "        X = np.array([]); y = np.array([])\n",
    "    \n",
    "    return X, y, file_ids\n",
    "\n",
    "\n",
    "print(\"‚úì fMRI preprocessing functions defined (optimized for young children ages 5-10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e84269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dparsf/filt_noglobal functional fMRI data for 372 young children...\n",
      "------------------------------------------------------------\n",
      "Downloading ABIDEII-EMC_1_0029864... [1] ‚úó ABIDEII-EMC_1_0029864 (Age: 9.0, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029866... [2] ‚úó ABIDEII-EMC_1_0029866 (Age: 8.7, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029867... [3] ‚úó ABIDEII-EMC_1_0029867 (Age: 8.5, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029869... [4] ‚úó ABIDEII-EMC_1_0029869 (Age: 8.8, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029870... [5] ‚úó ABIDEII-EMC_1_0029870 (Age: 8.6, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029871... [6] ‚úó ABIDEII-EMC_1_0029871 (Age: 7.5, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029872... [7] ‚úó ABIDEII-EMC_1_0029872 (Age: 9.1, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029873... [8] ‚úó ABIDEII-EMC_1_0029873 (Age: 6.8, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029874... [9] ‚úó ABIDEII-EMC_1_0029874 (Age: 7.3, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029875... [10] ‚úó ABIDEII-EMC_1_0029875 (Age: 8.4, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029876... [11] ‚úó ABIDEII-EMC_1_0029876 (Age: 8.9, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029877... [12] ‚úó ABIDEII-EMC_1_0029877 (Age: 7.9, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029878... [13] ‚úó ABIDEII-EMC_1_0029878 (Age: 8.2, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029879... [14] ‚úó ABIDEII-EMC_1_0029879 (Age: 8.0, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029880... [15] ‚úó ABIDEII-EMC_1_0029880 (Age: 6.2, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029881... [16] ‚úó ABIDEII-EMC_1_0029881 (Age: 6.5, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029882... [17] ‚úó ABIDEII-EMC_1_0029882 (Age: 6.8, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029883... [18] ‚úó ABIDEII-EMC_1_0029883 (Age: 7.5, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029884... [19] ‚úó ABIDEII-EMC_1_0029884 (Age: 8.2, ASD) - File not found on AWS S3\n",
      "Downloading ABIDEII-EMC_1_0029885... [20] ‚úó ABIDEII-EMC_1_0029885 (Age: 9.9, ASD) - File not found on AWS S3\n",
      "------------------------------------------------------------\n",
      "Download Summary: 0 succeeded, 20 failed\n",
      "‚úó No files downloaded. Cannot proceed with training.\n",
      "  Manual options:\n",
      "  1. Download ABIDE-II fMRI from: https://fcon_1000.projects.nitrc.org/indi/abide/\n",
      "  2. Place func_preproc files in ./abide2_fmri_data/\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 4: CHECK & LOAD ABIDE-II fMRI DATA (YOUNG CHILDREN)\n",
    "# ==============================\n",
    "# Checks for locally available functional preprocessed fMRI (func_preproc) for subjects aged 5-10 years\n",
    "# ‚ö†Ô∏è  FILES MUST BE MANUALLY DOWNLOADED FROM NITRC (see Cell 2 instructions)\n",
    "\n",
    "TARGET_SHAPE = (64, 64, 64)  # Standardized 3D fMRI volume size\n",
    "MAX_SAMPLES = 20  # Check first 20 subjects (or adjust as needed)\n",
    "DATA_DIR = \"./abide2_fmri_data\"\n",
    "PIPELINE = \"dparsf\"\n",
    "STRATEGY = \"filt_noglobal\"\n",
    "\n",
    "# Ensure phenotypic data is loaded and filtered for young children\n",
    "if 'df' not in locals() or 'df_filtered' not in locals():\n",
    "    print(\"ERROR: Phenotypic data not loaded. Run Cell 5 first.\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üì• DATA AVAILABILITY CHECK\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"‚ö†Ô∏è  ABIDE-II preprocessed data requires manual download from NITRC\")\n",
    "    print(f\"   Instructions: See Cell 2 (Problem Statement section)\\n\")\n",
    "    \n",
    "    print(f\"Checking for {PIPELINE}/{STRATEGY} functional fMRI files...\")\n",
    "    print(f\"Expected location: {DATA_DIR}/[FILE_ID]/[FILE_ID]_func_preproc.nii.gz\\n\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Check for existing local files\n",
    "    existing_files = []\n",
    "    missing_files = []\n",
    "    \n",
    "    for idx, (_, row) in enumerate(df_filtered.head(MAX_SAMPLES).iterrows()):\n",
    "        file_id = row['FILE_ID']\n",
    "        age = row['AGE_AT_SCAN']\n",
    "        dx = \"ASD\" if row['label'] == 1 else \"Control\"\n",
    "        \n",
    "        # Check for file in expected location\n",
    "        file_path = Path(DATA_DIR) / file_id / f\"{file_id}_func_preproc.nii.gz\"\n",
    "        \n",
    "        if file_path.exists():\n",
    "            existing_files.append((file_id, age, dx, str(file_path)))\n",
    "            print(f\"[{idx+1:2d}] ‚úì {file_id} (Age: {age:.1f}, {dx})\")\n",
    "        else:\n",
    "            missing_files.append((file_id, age, dx))\n",
    "            print(f\"[{idx+1:2d}] ‚úó {file_id} (Age: {age:.1f}, {dx}) - NOT FOUND\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    print(f\"\\nüìä SUMMARY:\")\n",
    "    print(f\"   Found: {len(existing_files)} / {MAX_SAMPLES} requested files\")\n",
    "    print(f\"   Missing: {len(missing_files)} / {MAX_SAMPLES} requested files\")\n",
    "    \n",
    "    # Load existing fMRI files into memory\n",
    "    if len(existing_files) > 0:\n",
    "        print(f\"\\nüîÑ Loading {len(existing_files)} preprocessed fMRI scans into memory...\")\n",
    "        X, y, file_ids = load_fmri_dataset(df_filtered.head(MAX_SAMPLES), DATA_DIR, \n",
    "                                           target_shape=TARGET_SHAPE, max_samples=MAX_SAMPLES)\n",
    "        \n",
    "        if len(X) > 0:\n",
    "            print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "            print(f\"   Shape: X={X.shape}, y={y.shape}\")\n",
    "            print(f\"   ASD samples: {int((y == 1).sum())}\")\n",
    "            print(f\"   Control samples: {int((y == 0).sum())}\")\n",
    "            print(f\"\\n‚úì Ready for training! Proceed to Cell 8.\")\n",
    "        else:\n",
    "            print(f\"‚ùå No fMRI files could be loaded. Check file paths and NIfTI format.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå NO FILES FOUND\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üì• REQUIRED ACTION:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"1. Register at: https://fcon_1000.projects.nitrc.org/indi/abide/\")\n",
    "        print(\"2. Download DPARSF filt_noglobal preprocessed files for subjects listed above\")\n",
    "        print(\"3. Extract files to ./abide2_fmri_data/ following this structure:\")\n",
    "        print(\"   ./abide2_fmri_data/\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ SITE_ID_SUBID/\")\n",
    "        print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ SITE_ID_SUBID_func_preproc.nii.gz\")\n",
    "        print(\"4. Re-run this cell to verify files are detected\")\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403c2862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ñπ fMRI data not yet loaded. Run Cell 4 first to download and load data.\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 5: VISUALIZE fMRI SAMPLES (YOUNG CHILDREN)\n",
    "# ==============================\n",
    "# Display 3D fMRI slices for representative ASD and Control subjects\n",
    "\n",
    "def visualize_fmri_slice(data_3d, title, cmap='gray'):\n",
    "    \"\"\"\n",
    "    Visualize 3D fMRI volume with 3 orthogonal slices\n",
    "    \n",
    "    Args:\n",
    "        data_3d: 3D numpy array (preprocessed fMRI)\n",
    "        title: Plot title\n",
    "        cmap: Colormap\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Get middle slice indices\n",
    "    d, h, w = data_3d.shape\n",
    "    z_mid, y_mid, x_mid = d // 2, h // 2, w // 2\n",
    "    \n",
    "    # Axial slice (horizontal)\n",
    "    axes[0].imshow(data_3d[z_mid, :, :], cmap=cmap)\n",
    "    axes[0].set_title(f\"Axial (z={z_mid})\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Coronal slice (front-to-back)\n",
    "    axes[1].imshow(data_3d[:, y_mid, :], cmap=cmap)\n",
    "    axes[1].set_title(f\"Coronal (y={y_mid})\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Sagittal slice (left-right)\n",
    "    axes[2].imshow(data_3d[:, :, x_mid], cmap=cmap)\n",
    "    axes[2].set_title(f\"Sagittal (x={x_mid})\")\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Check if fMRI data is loaded\n",
    "if 'X' in locals() and len(X) > 0:\n",
    "    print(\"Visualizing sample fMRI scans from young children dataset:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Find first ASD and Control samples\n",
    "    asd_idx = np.where(y == 1)[0]\n",
    "    control_idx = np.where(y == 0)[0]\n",
    "    \n",
    "    if len(asd_idx) > 0:\n",
    "        asd_sample = X[asd_idx[0], :, :, :, 0]  # Remove channel dimension\n",
    "        visualize_fmri_slice(asd_sample, f\"ASD Sample (ID: {file_ids[asd_idx[0]]})\")\n",
    "    else:\n",
    "        print(\"‚ö† No ASD samples available for visualization\")\n",
    "    \n",
    "    if len(control_idx) > 0:\n",
    "        control_sample = X[control_idx[0], :, :, :, 0]  # Remove channel dimension\n",
    "        visualize_fmri_slice(control_sample, f\"Control Sample (ID: {file_ids[control_idx[0]]})\")\n",
    "    else:\n",
    "        print(\"‚ö† No Control samples available for visualization\")\n",
    "else:\n",
    "    print(\"‚Ñπ fMRI data not yet loaded. Run Cell 4 first to download and load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261d88fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# STEP 6: TRAIN / TEST SPLIT\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mX\u001b[49m) > \u001b[32m0\u001b[39m:\n\u001b[32m      6\u001b[39m     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, stratify=y, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 6: TRAIN / TEST SPLIT\n",
    "# ==============================\n",
    "\n",
    "if len(X) > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape}\")\n",
    "    print(f\"Test set: {X_test.shape}\")\n",
    "    print(f\"Train - ASD: {np.sum(y_train)}, Control: {len(y_train)-np.sum(y_train)}\")\n",
    "    print(f\"Test - ASD: {np.sum(y_test)}, Control: {len(y_test)-np.sum(y_test)}\")\n",
    "else:\n",
    "    print(\"‚ùå No data available for train/test split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 7: BUILD 3D CNN MODEL\n",
    "# ==============================\n",
    "\n",
    "if len(X) > 0 and 'X_train' in locals():\n",
    "    def build_3d_cnn(input_shape):\n",
    "        \"\"\"Build 3D CNN for fMRI classification\"\"\"\n",
    "        model = Sequential([\n",
    "            Conv3D(32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "            BatchNormalization(),\n",
    "            Conv3D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling3D(pool_size=2),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Conv3D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Conv3D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling3D(pool_size=2),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Conv3D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling3D(pool_size=2),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            GlobalAveragePooling3D(),\n",
    "            Dense(256, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            Dense(128, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    model = build_3d_cnn(input_shape=X_train.shape[1:])\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    print(\"‚úì 3D CNN model built and compiled\")\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"‚ùå Cannot build model. Run cells 4-6 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb31386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 8: SETUP CALLBACKS\n",
    "# ==============================\n",
    "\n",
    "if 'model' in locals():\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "        ModelCheckpoint('best_3d_cnn_asd.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n",
    "    ]\n",
    "    print(\"‚úì Callbacks configured\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found. Run cell 7 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 9: TRAIN MODEL\n",
    "# ==============================\n",
    "\n",
    "if 'model' in locals() and 'callbacks' in locals():\n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE = 4\n",
    "    \n",
    "    print(f\"Training 3D CNN on {len(X_train)} subjects...\")\n",
    "    print(f\"Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}\\n\")\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=EPOCHS, \n",
    "                        batch_size=BATCH_SIZE, callbacks=callbacks, verbose=1)\n",
    "    print(\"\\n‚úì Training complete!\")\n",
    "else:\n",
    "    print(\"‚ùå Model or callbacks not found. Run cells 7-8 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816504bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 10: PLOT TRAINING HISTORY\n",
    "# ==============================\n",
    "\n",
    "if 'history' in locals():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    axes[0].plot(history.history['accuracy'], label='Train')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation')\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    axes[1].plot(history.history['loss'], label='Train')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation')\n",
    "    axes[1].set_title('Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    axes[2].plot(history.history['auc'], label='Train')\n",
    "    axes[2].plot(history.history['val_auc'], label='Validation')\n",
    "    axes[2].set_title('AUC')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('AUC')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå Training history not found. Run cell 9 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0153a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 11: EVALUATION\n",
    "# ==============================\n",
    "\n",
    "if 'model' in locals() and 'X_test' in locals():\n",
    "    y_pred_prob = model.predict(X_test).ravel()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    roc = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"3D CNN fMRI RESULTS (ABIDE-II)\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy: {acc:.2f}%\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Control', 'ASD']))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Control', 'ASD'], yticklabels=['Control', 'ASD'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå Model or test set not found. Run cells 6-9 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10413f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 12: SAVE MODEL\n",
    "# ==============================\n",
    "\n",
    "if 'model' in locals():\n",
    "    model.save(\"final_3d_cnn_asd_abide2.keras\")\n",
    "    print(\"‚úì Model saved: final_3d_cnn_asd_abide2.keras\")\n",
    "    \n",
    "    if 'history' in locals():\n",
    "        pd.DataFrame(history.history).to_csv(\"training_history_abide2.csv\", index=False)\n",
    "        print(\"‚úì History saved: training_history_abide2.csv\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e0586",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "1. **Download full ABIDE-II dataset** (500+ subjects)\n",
    "2. **Data augmentation**: Rotation, flipping for better generalization\n",
    "3. **Transfer learning**: Use pretrained 3D ResNet or Med3D\n",
    "4. **Ensemble**: Combine multiple models\n",
    "5. **Explainability**: Use GradCAM to visualize important brain regions\n",
    "\n",
    "## Important Notes:\n",
    "\n",
    "- **Memory**: 3D CNNs require significant GPU memory (8GB+ recommended)\n",
    "- **Training time**: Expect hours on CPU, minutes on GPU\n",
    "- **Data quality**: Preprocessing is critical for fMRI analysis\n",
    "- **Class imbalance**: Consider weighted loss or oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c1d92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Checklist written: C:\\Users\\eredd\\Desktop\\FYP\\abideII_5-10_download_checklist.csv\n",
      "  Total subjects: 372 | ASD: 168 | Control: 204\n",
      "‚úì Directory scaffold complete. Created 352 folders under abide2_fmri_data\n",
      "Place files using pattern: ./abide2_fmri_data/[FILE_ID]/[FILE_ID]_func_preproc.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# HELPER: Generate download checklist + scaffold directories\n",
    "# ==============================\n",
    "# Produces `abideII_5-10_download_checklist.csv` and creates per-subject folders in ./abide2_fmri_data/\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "if 'df_filtered' not in locals():\n",
    "    print(\"ERROR: Phenotypic data not loaded. Run Cell 5 first.\")\n",
    "else:\n",
    "    checklist = df_filtered[['FILE_ID','SITE_ID','AGE_AT_SCAN','label']].copy()\n",
    "    checklist['Diagnosis'] = checklist['label'].map({1:'ASD', 0:'Control'})\n",
    "    checklist = checklist[['FILE_ID','SITE_ID','AGE_AT_SCAN','Diagnosis']]\n",
    "\n",
    "    out_csv = Path('abideII_5-10_download_checklist.csv')\n",
    "    checklist.to_csv(out_csv, index=False)\n",
    "    print(f\"‚úì Checklist written: {out_csv.resolve()}\")\n",
    "    print(f\"  Total subjects: {len(checklist)} | ASD: {int((df_filtered['label']==1).sum())} | Control: {int((df_filtered['label']==0).sum())}\")\n",
    "\n",
    "    base = Path('./abide2_fmri_data')\n",
    "    base.mkdir(exist_ok=True)\n",
    "    created = 0\n",
    "    for fid in df_filtered['FILE_ID'].tolist():\n",
    "        d = base / fid\n",
    "        if not d.exists():\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "            created += 1\n",
    "    print(f\"‚úì Directory scaffold complete. Created {created} folders under {base}\")\n",
    "    print(\"Place files using pattern: ./abide2_fmri_data/[FILE_ID]/[FILE_ID]_func_preproc.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f44a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded ABIDE-I phenotypic data: 1112 subjects\n",
      "Young children (ABIDE-I, 5-10y): 150\n",
      "\n",
      "Attempting downloads from S3: pipelines=['cpac', 'dparsf'], strategy=filt_noglobal\n",
      "[01] ‚úì KKI_0050776 (Age 9.3, Control)\n",
      "[02] ‚úì KKI_0050777 (Age 8.4, Control)\n",
      "[03] ‚úì KKI_0050778 (Age 9.7, Control)\n",
      "[04] ‚úì KKI_0050779 (Age 9.4, Control)\n",
      "[05] ‚úì KKI_0050780 (Age 9.8, Control)\n",
      "[06] ‚úì KKI_0050781 (Age 9.3, Control)\n",
      "[07] ‚úì KKI_0050784 (Age 8.1, Control)\n",
      "[08] ‚úì KKI_0050786 (Age 8.8, Control)\n",
      "[09] ‚úì KKI_0050789 (Age 9.3, Control)\n",
      "[10] ‚úì KKI_0050790 (Age 8.8, Control)\n",
      "\n",
      "Summary: 10 succeeded, 0 failed\n",
      "\n",
      "‚úì ABIDE-I dataset loaded: X=(10, 64, 64, 64, 1), y=(10,)\n",
      "   ASD: 0 | Control: 10\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# OPTION 2: Use ABIDE-I (AWS S3) for automatic downloads\n",
    "# ==============================\n",
    "# Loads ABIDE-I phenotypic data and downloads preprocessed functional fMRI\n",
    "# Tries cpac then dparsf with filt_noglobal from fcp-indi S3 (public)\n",
    "\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ABIDE1_PHENO = \"Phenotypic_V1_0b.csv\"\n",
    "ABIDE1_DATA_DIR = \"./abide1_fmri_data\"\n",
    "PIPELINES = [\"cpac\", \"dparsf\"]  # S3 uses lowercase pipeline names\n",
    "STRATEGY = \"filt_noglobal\"\n",
    "ABIDE1_MAX_SAMPLES = 10\n",
    "BASE_URL = \"https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs\"\n",
    "\n",
    "# Downloader that tries multiple pipelines\n",
    "def download_abide1_fmri_s3(file_id, output_dir=ABIDE1_DATA_DIR):\n",
    "    out_dir = Path(output_dir) / file_id\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_file = out_dir / f\"{file_id}_func_preproc.nii.gz\"\n",
    "\n",
    "    if out_file.exists():\n",
    "        return str(out_file)\n",
    "\n",
    "    for pipeline in PIPELINES:\n",
    "        url = f\"{BASE_URL}/{pipeline}/{STRATEGY}/func_preproc/{file_id}_func_preproc.nii.gz\"\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, out_file)\n",
    "            return str(out_file)\n",
    "        except Exception:\n",
    "            if out_file.exists():\n",
    "                out_file.unlink()\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# Load ABIDE-I phenotypic\n",
    "try:\n",
    "    df1 = pd.read_csv(ABIDE1_PHENO)\n",
    "    df1.columns = df1.columns.str.strip()\n",
    "    print(f\"‚úì Loaded ABIDE-I phenotypic data: {df1.shape[0]} subjects\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Missing {ABIDE1_PHENO}. Please place it in the workspace.\")\n",
    "\n",
    "# Labels and FILE_ID\n",
    "if 'df1' in locals():\n",
    "    df1['label'] = df1['DX_GROUP'].map({1:1, 2:0})\n",
    "    df1 = df1.dropna(subset=['label'])\n",
    "    df1['FILE_ID'] = df1['SITE_ID'].astype(str) + '_' + df1['SUB_ID'].astype(str).str.zfill(7)\n",
    "\n",
    "    MIN_AGE, MAX_AGE = 5, 10\n",
    "    df1f = df1[(df1['AGE_AT_SCAN'] >= MIN_AGE) & (df1['AGE_AT_SCAN'] <= MAX_AGE)].copy()\n",
    "    print(f\"Young children (ABIDE-I, {MIN_AGE}-{MAX_AGE}y): {len(df1f)}\")\n",
    "    if len(df1f) == 0:\n",
    "        print(\"‚ö†Ô∏è No 5-10 y subjects in ABIDE-I. Using first N subjects for testing downloads.\")\n",
    "        df1f = df1.head(ABIDE1_MAX_SAMPLES).copy()\n",
    "\n",
    "    print(f\"\\nAttempting downloads from S3: pipelines={PIPELINES}, strategy={STRATEGY}\")\n",
    "    ok, fail = 0, 0\n",
    "    for i, (_, row) in enumerate(df1f.head(ABIDE1_MAX_SAMPLES).iterrows(), start=1):\n",
    "        fid = row['FILE_ID']\n",
    "        age = row['AGE_AT_SCAN']\n",
    "        dx = 'ASD' if row['label']==1 else 'Control'\n",
    "        path = download_abide1_fmri_s3(fid)\n",
    "        if path:\n",
    "            ok += 1\n",
    "            print(f\"[{i:02d}] ‚úì {fid} (Age {age:.1f}, {dx})\")\n",
    "        else:\n",
    "            fail += 1\n",
    "            print(f\"[{i:02d}] ‚úó {fid} (Age {age:.1f}, {dx}) - not found on S3 (cpac/dparsf)\")\n",
    "\n",
    "    print(f\"\\nSummary: {ok} succeeded, {fail} failed\")\n",
    "\n",
    "    # Load successfully downloaded files (if any)\n",
    "    if ok > 0:\n",
    "        X1, y1, fids1 = load_fmri_dataset(df1f.head(ABIDE1_MAX_SAMPLES), ABIDE1_DATA_DIR, target_shape=(64,64,64), max_samples=ABIDE1_MAX_SAMPLES)\n",
    "        if len(X1) > 0:\n",
    "            print(f\"\\n‚úì ABIDE-I dataset loaded: X={X1.shape}, y={y1.shape}\")\n",
    "            print(f\"   ASD: {int((y1==1).sum())} | Control: {int((y1==0).sum())}\")\n",
    "        else:\n",
    "            print(\"‚ùå Downloaded files could not be loaded. Check file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c1ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ABIDE-I loaded: 1112 subjects (sampling 30)\n",
      "‚úì ABIDE-II loaded: 1114 subjects (sampling 30)\n",
      "\n",
      "Verifying ABIDE-I S3 access (30 samples)...\n",
      "  [10/30] CALTECH_0051465: not_found\n",
      "  [20/30] CALTECH_0051475: not_found\n",
      "  [30/30] CALTECH_0051485: not_found\n",
      "‚úì ABIDE-I: 0/30 accessible via S3\n",
      "\n",
      "Verifying ABIDE-II S3 check (30 samples)...\n",
      "  [10/30] ABIDEII-BNI_1_0029025: not_found\n",
      "  [20/30] ABIDEII-BNI_1_0029042: not_found\n",
      "  [30/30] ABIDEII-BNI_1_0029011: not_found\n",
      "‚úì ABIDE-II: 0/30 accessible via S3 (expected 0)\n",
      "\n",
      "üìÑ Report saved: C:\\Users\\eredd\\Desktop\\FYP\\remote_access_report.csv\n",
      "\n",
      "Summary:\n",
      "                    count\n",
      "source   status          \n",
      "ABIDE-I  not_found     30\n",
      "ABIDE-II not_found     30\n",
      "\n",
      "First 10 entries:\n",
      " source         FILE_ID diagnosis    status pipeline\n",
      "ABIDE-I CALTECH_0051456       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051457       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051458       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051459       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051460       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051461       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051462       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051463       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051464       ASD not_found     None\n",
      "ABIDE-I CALTECH_0051465       ASD not_found     None\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# REMOTE ACCESS VERIFIER: ABIDE-I (S3) and ABIDE-II (NITRC/S3)\n",
    "# ==============================\n",
    "# Checks URL accessibility without downloading. Fast sampling mode.\n",
    "# - ABIDE-I: Public S3 (pipelines: cpac, dparsf)\n",
    "# - ABIDE-II: Expected not on S3 (NITRC requires login)\n",
    "\n",
    "import urllib.request, urllib.error\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ABIDE1_PHENO = \"Phenotypic_V1_0b.csv\"\n",
    "ABIDE2_PHENO = \"ABIDEII_Composite_Phenotypic.csv\"\n",
    "S3_BASE = \"https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs\"\n",
    "PIPELINES = [\"cpac\", \"dparsf\"]\n",
    "STRATEGIES = [\"filt_noglobal\"]\n",
    "DERIVATIVE = \"func_preproc\"\n",
    "SAMPLE_SIZE = 30  # Check only first 30 subjects per dataset for speed\n",
    "\n",
    "REPORT_CSV = Path(\"remote_access_report.csv\")\n",
    "\n",
    "def url_head_exists(url: str, timeout: int = 5):\n",
    "    try:\n",
    "        req = urllib.request.Request(url, method='HEAD')\n",
    "        with urllib.request.urlopen(req, timeout=timeout) as resp:\n",
    "            return True, resp.status\n",
    "    except urllib.error.HTTPError as e:\n",
    "        return False, e.code\n",
    "    except Exception:\n",
    "        return False, None\n",
    "\n",
    "# Load phenotypes\n",
    "df1, df2 = None, None\n",
    "try:\n",
    "    df1 = pd.read_csv(ABIDE1_PHENO)\n",
    "    df1.columns = df1.columns.str.strip()\n",
    "    df1['label'] = df1['DX_GROUP'].map({1:1, 2:0})\n",
    "    df1 = df1.dropna(subset=['label'])\n",
    "    df1['FILE_ID'] = df1['SITE_ID'].astype(str) + '_' + df1['SUB_ID'].astype(str).str.zfill(7)\n",
    "    print(f\"‚úì ABIDE-I loaded: {len(df1)} subjects (sampling {SAMPLE_SIZE})\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not load {ABIDE1_PHENO}: {e}\")\n",
    "\n",
    "try:\n",
    "    df2 = pd.read_csv(ABIDE2_PHENO, encoding='latin1')\n",
    "    df2.columns = df2.columns.str.strip()\n",
    "    df2['label'] = df2['DX_GROUP'].map({1:1, 2:0})\n",
    "    df2 = df2.dropna(subset=['label'])\n",
    "    df2['FILE_ID'] = df2['SITE_ID'].astype(str) + '_' + df2['SUB_ID'].astype(str).str.zfill(7)\n",
    "    print(f\"‚úì ABIDE-II loaded: {len(df2)} subjects (sampling {SAMPLE_SIZE})\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not load {ABIDE2_PHENO}: {e}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Verify ABIDE-I (public S3) - SAMPLE ONLY\n",
    "if df1 is not None:\n",
    "    print(f\"\\nVerifying ABIDE-I S3 access ({SAMPLE_SIZE} samples)...\")\n",
    "    for i, (_, r) in enumerate(df1.head(SAMPLE_SIZE).iterrows(), start=1):\n",
    "        fid = r['FILE_ID']\n",
    "        age = r.get('AGE_AT_SCAN', None)\n",
    "        diagnosis = 'ASD' if int(r['label']) == 1 else 'Control'\n",
    "        status = 'not_found'\n",
    "        chosen_pipeline = None\n",
    "        url_used = None\n",
    "        \n",
    "        for pipe in PIPELINES:\n",
    "            for strat in STRATEGIES:\n",
    "                url = f\"{S3_BASE}/{pipe}/{strat}/{DERIVATIVE}/{fid}_{DERIVATIVE}.nii.gz\"\n",
    "                ok, code = url_head_exists(url)\n",
    "                if ok:\n",
    "                    status = 'accessible'\n",
    "                    chosen_pipeline = pipe\n",
    "                    url_used = url\n",
    "                    break\n",
    "            if status == 'accessible':\n",
    "                break\n",
    "        \n",
    "        rows.append({\n",
    "            'source': 'ABIDE-I',\n",
    "            'FILE_ID': fid,\n",
    "            'age': age,\n",
    "            'diagnosis': diagnosis,\n",
    "            'status': status,\n",
    "            'pipeline': chosen_pipeline,\n",
    "            'strategy': strat if chosen_pipeline else None,\n",
    "            'url': url_used\n",
    "        })\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  [{i}/{SAMPLE_SIZE}] {fid}: {status}\")\n",
    "    \n",
    "    accessible = sum(1 for r in rows if r['source']=='ABIDE-I' and r['status']=='accessible')\n",
    "    print(f\"‚úì ABIDE-I: {accessible}/{SAMPLE_SIZE} accessible via S3\")\n",
    "\n",
    "# Verify ABIDE-II (expected not on S3) - SAMPLE ONLY\n",
    "if df2 is not None:\n",
    "    print(f\"\\nVerifying ABIDE-II S3 check ({SAMPLE_SIZE} samples)...\")\n",
    "    for i, (_, r) in enumerate(df2.head(SAMPLE_SIZE).iterrows(), start=1):\n",
    "        fid = r['FILE_ID']\n",
    "        age = r.get('AGE_AT_SCAN', None)\n",
    "        diagnosis = 'ASD' if int(r['label']) == 1 else 'Control'\n",
    "        fid_s3 = fid.replace('ABIDEII-', '') if fid.startswith('ABIDEII-') else fid\n",
    "        url = f\"{S3_BASE}/dparsf/filt_noglobal/{DERIVATIVE}/{fid_s3}_{DERIVATIVE}.nii.gz\"\n",
    "        ok, code = url_head_exists(url)\n",
    "        status = 'accessible' if ok else ('forbidden' if code == 403 else 'not_found')\n",
    "        \n",
    "        rows.append({\n",
    "            'source': 'ABIDE-II',\n",
    "            'FILE_ID': fid,\n",
    "            'age': age,\n",
    "            'diagnosis': diagnosis,\n",
    "            'status': status,\n",
    "            'pipeline': 'dparsf',\n",
    "            'strategy': 'filt_noglobal',\n",
    "            'url': url\n",
    "        })\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  [{i}/{SAMPLE_SIZE}] {fid}: {status}\")\n",
    "    \n",
    "    accessible = sum(1 for r in rows if r['source']=='ABIDE-II' and r['status']=='accessible')\n",
    "    print(f\"‚úì ABIDE-II: {accessible}/{SAMPLE_SIZE} accessible via S3 (expected 0)\")\n",
    "\n",
    "report = pd.DataFrame(rows)\n",
    "report.to_csv(REPORT_CSV, index=False)\n",
    "\n",
    "print(f\"\\nüìÑ Report saved: {REPORT_CSV.resolve()}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(report.groupby(['source','status']).size().to_frame('count'))\n",
    "print(f\"\\nFirst 10 entries:\")\n",
    "print(report.head(10)[['source','FILE_ID','diagnosis','status','pipeline']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
